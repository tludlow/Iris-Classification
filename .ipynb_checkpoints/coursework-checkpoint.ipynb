{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset\n",
    "[coursework doc](https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs342/coursework_cs342_2020-2021.pdf)\n",
    "[iterative process](https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs342/iterativeprocess.pdf)\n",
    "\n",
    "Dataset information:\n",
    "1) sepal length in cm \n",
    "2) sepal width in cm\n",
    "3) petal length in cm\n",
    "4) petal width in cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3               4\n",
      "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
      "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
      "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
      "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
      "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
      "..   ...  ...  ...  ...             ...\n",
      "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
      "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
      "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
      "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
      "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "#import the flower data\n",
    "df = pd.read_csv(\"./iris.data\", header=None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method A\n",
    "Convert the 4D data into 2D using PCA and visualise, based on SVD from lab 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Code from lab 5 for PCA using SVD, uses preprocessing from sklearn to centre the data\n",
    "def pca_decomposition(dataset):\n",
    "    data_centred = (dataset - dataset.mean()) / dataset.std()\n",
    "#     data_scaled = preprocessing.scale(dataset)\n",
    "    U, s, V = np.linalg.svd(data_centred, full_matrices=True)\n",
    "    return U, s, V\n",
    "\n",
    "x_features = df[df.columns[:-1]]\n",
    "x_label = df[df.columns[-1]]\n",
    "U, s, V = pca_decomposition(x_features)\n",
    "\n",
    "\n",
    "projected_U = U[:, :2] #only take the first 2 components because we want 2D reduction\n",
    "projected_U *= s[:2] #you do X * V to project data which is equivalent to U * S so we can just do that (apparently it's quicker)\n",
    "\n",
    "dimension_reduced_iris = pd.DataFrame(data = projected_U, columns = ['PC1', 'PC2'])\n",
    "#add the labels back to the data so it can be used in the graph..\n",
    "dimension_reduced_iris[\"label\"] = x_label\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "#setosa\n",
    "setosa = dimension_reduced_iris.loc[dimension_reduced_iris['label'] == \"Iris-setosa\"]\n",
    "plt.scatter(setosa[\"PC1\"], setosa[\"PC2\"], c=\"r\", marker=\"o\")\n",
    "\n",
    "#versicolor\n",
    "versicolor = dimension_reduced_iris.loc[dimension_reduced_iris['label'] == \"Iris-versicolor\"]\n",
    "plt.scatter(versicolor[\"PC1\"], versicolor[\"PC2\"], c=\"b\", marker=\"o\")\n",
    "\n",
    "#virginica\n",
    "virginica = dimension_reduced_iris.loc[dimension_reduced_iris['label'] == \"Iris-virginica\"]\n",
    "plt.scatter(virginica[\"PC1\"], virginica[\"PC2\"], c=\"g\", marker=\"o\")\n",
    "\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.legend([\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method B\n",
    "Multi class perceptron on the 2d subspace. Make sure to encourage the largest predicted value to be the correct classification. Use the lab as a starting point.\n",
    "\n",
    "\n",
    "### Hints\n",
    "1) Define the class labels as numerical values, e.g., use 0, 1 and 2, for the three labels.\n",
    "2) Determine how to update the weights of the linear classifier that provides the maximum predicted value and those of the\n",
    "linear classifier associated with the correct class when the prediction is incorrect.\n",
    "3) Recall adding a bias to the linear classifiers.\n",
    "4) The algorithm may need to run for several iterations, as the data is not linearly separable. In each iteration, all training\n",
    "samples should be used in random order. Train your"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the dataset labels into numbers rather than text\n",
    "0 = Iris-setosa\n",
    "1 = Iris-versicolor\n",
    "2 = Iris-virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "df[4].replace('Iris-setosa',0,inplace=True)\n",
    "df[4].replace('Iris-versicolor',1,inplace=True)\n",
    "df[4].replace('Iris-virginica',2,inplace=True)\n",
    "\n",
    "class MultiClassPerceptron():\n",
    "    def __init__(self, data, classes, iterations):\n",
    "        self.data = data\n",
    "        self.classes = classes\n",
    "        self.iterations = iterations\n",
    "         \n",
    "        #Create the weights for each classes with a bias term of 1 at the 0 index for each weight vector\n",
    "        #Has the label included at this point and not the bias so it balanced out in size\n",
    "        feature_count = len(self.data[0])\n",
    "        self.weights = {}\n",
    "        for i in self.classes:\n",
    "            self.weights[i] = [0 for i in range(feature_count)]\n",
    "            \n",
    "        #Add the bias (1) to each of the feature vectors for all training examples\n",
    "        for idx, feature_vector in enumerate(self.data):\n",
    "            self.data[idx] = [1] + self.data[idx]\n",
    "        \n",
    "    def train(self):\n",
    "        #Run the training for the specified number of iterations\n",
    "        for iteration in range(self.iterations):\n",
    "            random.shuffle(self.data)\n",
    "            \n",
    "            for n in self.data:\n",
    "                features = n[:-1]\n",
    "                label = int(n[-1:][0])\n",
    "                \n",
    "                #current largest predicted value\n",
    "                argmax = 0\n",
    "                #current predicted class\n",
    "                predicted_class = self.classes[0]\n",
    "                \n",
    "                #classify the training examples for all classifiers (each class)\n",
    "                for idx, c in enumerate(self.classes):\n",
    "                    classification = np.dot(self.weights[c], features)\n",
    "                    \n",
    "                    if classification >= argmax:\n",
    "                        argmax = classification\n",
    "                        predicted_class = c\n",
    "                        #print(\"Classification for classifier \" + str(c) + \" = \" + str(classification) + \" actual (\" + str(label) + \")\")\n",
    "                \n",
    "                #Refine the solution if the prediction is wrong\n",
    "                if not (str(predicted_class) == str(label)):\n",
    "                    self.weights[str(label)] += np.array(features)\n",
    "                    self.weights[str(predicted_class)] -= np.array(features)\n",
    "                    #Restart on all the examples again (without shuffling)\n",
    "                    continue\n",
    "    \n",
    "    def predict(self, features):\n",
    "        #add the bias\n",
    "        features = [1] + features\n",
    "        \n",
    "        argmax = 0\n",
    "        predicted_class = self.classes[0]\n",
    "        \n",
    "        #for each classifier run it on the example only returning the largest predicted value\n",
    "        for c in self.classes:\n",
    "            classification = np.dot(self.weights[c], features)\n",
    "            if classification >= argmax:\n",
    "                argmax = classification\n",
    "                predicted_class = c\n",
    "            \n",
    "        return predicted_class\n",
    "    \n",
    "    def get_weights(self):\n",
    "        return self.weights\n",
    "        \n",
    "features = df.iloc[:,:-1].values.tolist()\n",
    "labels = df.iloc[:,-1:].values.tolist()\n",
    "\n",
    "accuracy_results = []\n",
    "mcp = MultiClassPerceptron(df.values.tolist(), [\"0\", \"1\", \"2\"], 50)\n",
    "mcp.train()\n",
    "\n",
    "inaccurate_predictions = 0\n",
    "for i in df.values.tolist():\n",
    "    prediction = int(mcp.predict(i[:-1]))\n",
    "    actual = int(i[-1:][0])\n",
    "    if actual != prediction:\n",
    "        inaccurate_predictions += 1\n",
    "\n",
    "print(inaccurate_predictions)\n",
    "accuracy = (150-inaccurate_predictions)/150\n",
    "print(\"Accuracy: \" + str(accuracy))\n",
    "accuracy_results.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2D Multiclass perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Accuracy: 0.9266666666666666\n"
     ]
    }
   ],
   "source": [
    "projected_list = projected_U.tolist()\n",
    "for idx, label in enumerate(labels):\n",
    "    projected_list[idx].append(label[0])\n",
    "\n",
    "accuracy_results = []\n",
    "\n",
    "twod_mcp = MultiClassPerceptron(projected_list, [\"0\", \"1\", \"2\"], 50)\n",
    "twod_mcp.train()\n",
    "\n",
    "    # fig = plt.figure(figsize=(5, 4))\n",
    "    # ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "    # #setosa\n",
    "    # setosa = dimension_reduced_iris.loc[dimension_reduced_iris['label'] == \"Iris-setosa\"]\n",
    "    # plt.scatter(setosa[\"PC1\"], setosa[\"PC2\"], c=\"r\", marker=\"o\")\n",
    "\n",
    "    # #versicolor\n",
    "    # versicolor = dimension_reduced_iris.loc[dimension_reduced_iris['label'] == \"Iris-versicolor\"]\n",
    "    # plt.scatter(versicolor[\"PC1\"], versicolor[\"PC2\"], c=\"b\", marker=\"o\")\n",
    "\n",
    "    # #virginica\n",
    "    # virginica = dimension_reduced_iris.loc[dimension_reduced_iris['label'] == \"Iris-virginica\"]\n",
    "    # plt.scatter(virginica[\"PC1\"], virginica[\"PC2\"], c=\"g\", marker=\"o\")\n",
    "\n",
    "    # new_x_data = []\n",
    "    # new_y_data = []\n",
    "\n",
    "    # for i in projected_list:\n",
    "    #     new_x_data.append(i[1])\n",
    "    #     new_y_data.append(i[2])\n",
    "\n",
    "    # for i in range(3):\n",
    "    #     #calculate the decision boundaries\n",
    "\n",
    "    #     x0_1 = np.amin(new_x_data)\n",
    "    #     x0_2 = np.amax(new_x_data)\n",
    "    #     x1_1 = (-twod_mcp.get_weights()[str(i)][1] * x0_1 - twod_mcp.get_weights()[str(i)][0]) / twod_mcp.get_weights()[str(i)][2]\n",
    "    #     x1_2 = (-twod_mcp.get_weights()[str(i)][1] * x0_2 - twod_mcp.get_weights()[str(i)][0]) / twod_mcp.get_weights()[str(i)][2]\n",
    "\n",
    "    #     ax.plot([x0_1, x0_2],[x1_1, x1_2])\n",
    "\n",
    "\n",
    "    # plt.xlabel(\"PC1\")\n",
    "    # plt.ylabel(\"PC2\")\n",
    "    # plt.legend([\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"])\n",
    "    # plt.ylim([-3,3])\n",
    "    # plt.show()\n",
    "\n",
    "inaccurate_predictions = 0\n",
    "for i in projected_list:\n",
    "    prediction = int(twod_mcp.predict(i[1:-1]))\n",
    "    actual = i[3]\n",
    "    if actual != prediction:\n",
    "        inaccurate_predictions += 1\n",
    "        \n",
    "print(inaccurate_predictions)\n",
    "accuracy = (150-inaccurate_predictions)/150\n",
    "print(\"Accuracy: \" + str(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int32') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-f8a297b2bc1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m             ]\n\u001b[0;32m      6\u001b[0m \u001b[0mothermcp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultiClassPerceptron\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"0\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mothermcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-7abeff73e129>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_class\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m                     \u001b[1;31m#Restart on all the examples again (without shuffling)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'subtract' output from dtype('float64') to dtype('int32') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "random_list=[\n",
    "             [1, 1, 0], [1.6, 2.8, 0], [1.5, 3, 0], [1.3, 1.4, 0], [1.1, 1.2, 0],\n",
    "             [2, 4, 1], [3, 2, 1], [2.1, 3, 1], [2.4, 4, 1], [2.7, 2, 1],\n",
    "             [1, 5, 2], [3, 6, 2], [2.1, 7, 2], [1.1, 8, 2], [2.7, 9, 2],\n",
    "            ]\n",
    "othermcp = MultiClassPerceptron(random_list, [\"0\", \"1\", \"2\"], 50)\n",
    "othermcp.train()\n",
    "\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "plt.scatter([1, 1.6, 1.5, 1.3, 1.1], [1, 2.8, 3, 1.4, 1.2], c=\"r\", marker=\"o\")\n",
    "\n",
    "plt.scatter([2, 3, 2.1, 2.4, 2.7], [4, 2, 3, 4, 2], c=\"b\", marker=\"o\")\n",
    "\n",
    "plt.scatter([1, 3, 2.1, 1.1, 2.7], [5, 6, 7, 8, 9], c=\"g\", marker=\"o\")\n",
    "# for i in range(3):\n",
    "#     #calculate the decision boundaries\n",
    "    \n",
    "#     x0_1 = np.amin(new_x_data)\n",
    "#     x0_2 = np.amax(new_x_data)\n",
    "#     x1_1 = (-twod_mcp.get_weights()[str(i)][1] * x0_1 - twod_mcp.get_weights()[str(i)][0]) / twod_mcp.get_weights()[str(i)][2]\n",
    "#     x1_2 = (-twod_mcp.get_weights()[str(i)][1] * x0_2 - twod_mcp.get_weights()[str(i)][0]) / twod_mcp.get_weights()[str(i)][2]\n",
    "\n",
    "#     ax.plot([x0_1, x0_2],[x1_1, x1_2])\n",
    "\n",
    "\n",
    "plt.legend([\"1\", \"2\", \"3\"])\n",
    "plt.show()\n",
    "\n",
    "inaccurate_predictions = 0\n",
    "for i in projected_list:\n",
    "    prediction = int(othermcp.predict(i[1:-1]))\n",
    "    actual = i[3]\n",
    "    if actual != prediction:\n",
    "        inaccurate_predictions += 1\n",
    "\n",
    "print(inaccurate_predictions)\n",
    "accuracy = (15-inaccurate_predictions)/15\n",
    "print(\"Accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Method\n",
    "Projecting the data onto a higher dimensional subspace so that, hopefully, the data becomes seperable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0625, 0.0625, 0.0625, 0.0625], [0.0625, 0.0625, 0.0625, 0.0625], [0.0625, 0.0625, 0.0625, 0.0625], [0.0625, 0.0625, 0.0625, 0.0625]]\n"
     ]
    }
   ],
   "source": [
    "#Creating the kernel matrix, it is the dot product between all examples in the data set\n",
    "    \n",
    "#Computes the kernel matrix K (nxn)\n",
    "def computeKernelMatrix(data):\n",
    "    K = []\n",
    "    for idx, i in enumerate(data):\n",
    "        K.append([])\n",
    "        for idxTwo, j in enumerate(data):\n",
    "            K[idx].append(np.dot(i, j))\n",
    "            \n",
    "    return K\n",
    "            \n",
    "def computeNormalisedKernelMatrix(K):\n",
    "    #Need to generate the A matrix which is an nxn matrix with all values set to 1/n (n being training sample size)\n",
    "    A = []\n",
    "    n = len(np.array(K).flatten())\n",
    "    for i in range(int(math.sqrt(n))):\n",
    "        A.append([])\n",
    "        for j in range(int(math.sqrt(n))):\n",
    "            A[i].append(1/n)\n",
    "            \n",
    "    print(A)\n",
    "\n",
    "\n",
    "K = computeKernelMatrix([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "computeNormalisedKernelMatrix(K)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
